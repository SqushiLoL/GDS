{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Analyze the Fake News Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Mariu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words in raw text: 20948\n",
      "unique words in cleaned text: 16608\n",
      "type\n",
      "fake        186\n",
      "reliable     21\n",
      "Name: count, dtype: int64\n",
      "type\n",
      "fake        0.898551\n",
      "reliable    0.101449\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1: Import Dataset\n",
    "\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from cleantext import clean\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# 1: Read the CSV file and save the original\n",
    "df = pd.read_csv(\"news_sample.csv\")\n",
    "\n",
    "# Save the original raw text before cleaning\n",
    "df['raw_content'] = df['content']\n",
    "\n",
    "def clean_text_lib(text):\n",
    "   return clean(text,\n",
    "               lower=True,\n",
    "               no_line_breaks=True,\n",
    "               no_urls=True,\n",
    "               no_emails=True,\n",
    "               no_numbers=True,\n",
    "               no_punct=True)\n",
    "    \n",
    "# 2: Clean the data \n",
    "df['clean_content'] = df['content'].apply(lambda x: clean_text_lib(x) if isinstance(x, str) else \"\")\n",
    "\n",
    "# 3: get all raw data from 'content'\n",
    "raw_text = \" \".join(df['content'].dropna().tolist())\n",
    "raw_tokens = word_tokenize(raw_text)\n",
    "unique_raw_words = set(raw_tokens)\n",
    "print(\"unique words in raw text:\", len(unique_raw_words))\n",
    "\n",
    "# Get all cleaned text from the new \"clean_content\" \n",
    "clean_text_all = \" \".join(df['clean_content'].dropna().tolist())\n",
    "clean_tokens = word_tokenize(clean_text_all)\n",
    "unique_clean_words = set(clean_tokens)\n",
    "print(\"unique words in cleaned text:\", len(unique_clean_words))\n",
    "\n",
    "# number of each word in cleaned text\n",
    "word_freq = Counter(clean_tokens)\n",
    "most_common_50 = word_freq.most_common(50)\n",
    "\n",
    "# Extract words and frequencies\n",
    "words, frequencies = zip(*most_common_50)\n",
    "\n",
    "# Plot the 50 most frequent words\n",
    "#plt.figure(figsize=(15, 5))\n",
    "#plt.bar(words, frequencies)\n",
    "#plt.xlabel(\"Words\")\n",
    "#plt.ylabel(\"Frequency\")\n",
    "#plt.title(\"50 Most frequent words in cleaned text\")\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2: Dataset Analysis\n",
    "\n",
    "# A: Determine which article types should be omitted, if any.\n",
    "\n",
    "# leave out satire (just humor)\n",
    "df = df[df['type'] != 'satire']\n",
    "# Has no data\n",
    "df = df[df['type'] != 'state']\n",
    "# misleading science\n",
    "df = df[df['type'] != 'junksci']\n",
    "# not reliable, just hate\n",
    "df = df[df['type'] != 'hate']\n",
    "# exaggerated\n",
    "df = df[df['type'] != 'clickbait']\n",
    "# specefic viewpoint\n",
    "df = df[df['type'] != 'political']\n",
    "\n",
    "\n",
    "\n",
    "# B: Group the remaining types into 'fake' and 'reliable'. Argue for your choice.\n",
    "\n",
    "# fake\n",
    "df['type'] = df['type'].replace(['conspiracy', 'fake'], 'fake')\n",
    "\n",
    "\n",
    "#reliable\n",
    "df['type'] = df['type'].replace(['unreliable', 'bias', 'unreliable', 'unknown'], 'reliable')\n",
    "print(df['type'].value_counts())\n",
    "\n",
    "# C: Examine the percentage distribution of 'reliable' vs. 'fake' articles. Is the dataset balanced? Discuss the importance of a balanced distribution.\n",
    "\n",
    "# reliable vs fake - percentage\n",
    "print(df['type'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Gathering Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cookies rejected.\n",
      "\n",
      "--- Scraping region: world/europe ---\n",
      "Extracted 48 articles from this page.\n"
     ]
    },
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: Element <button class=\"sc-944f9211-1 sc-944f9211-2 RZsRF gBqyGL\"> is not clickable at point (821,916) because another element <div class=\"orb-banner-content\"> obscures it\nStacktrace:\nRemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:197:5\nElementClickInterceptedError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:342:5\nwebdriverClickElement@chrome://remote/content/marionette/interaction.sys.mjs:177:11\ninteraction.clickElement@chrome://remote/content/marionette/interaction.sys.mjs:136:11\nclickElement@chrome://remote/content/marionette/actors/MarionetteCommandsChild.sys.mjs:344:29\nreceiveMessage@chrome://remote/content/marionette/actors/MarionetteCommandsChild.sys.mjs:220:31\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 144\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Scraping region: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    143\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.bbc.com/news/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 144\u001b[0m region_articles \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_region\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbrowser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m all_articles\u001b[38;5;241m.\u001b[39mextend(region_articles)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Brief pause between regions\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 101\u001b[0m, in \u001b[0;36mscrape_region\u001b[1;34m(driver, url)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Click the next button\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m \u001b[43mnext_button\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m page_number \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClicked \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNext Page\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m -> now on page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Mariu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:119\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Clicks the element.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    >>> element.click()\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLICK_ELEMENT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mariu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:572\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    570\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    571\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 572\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mariu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Mariu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:232\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    230\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: Element <button class=\"sc-944f9211-1 sc-944f9211-2 RZsRF gBqyGL\"> is not clickable at point (821,916) because another element <div class=\"orb-banner-content\"> obscures it\nStacktrace:\nRemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\nWebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:197:5\nElementClickInterceptedError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:342:5\nwebdriverClickElement@chrome://remote/content/marionette/interaction.sys.mjs:177:11\ninteraction.clickElement@chrome://remote/content/marionette/interaction.sys.mjs:136:11\nclickElement@chrome://remote/content/marionette/actors/MarionetteCommandsChild.sys.mjs:344:29\nreceiveMessage@chrome://remote/content/marionette/actors/MarionetteCommandsChild.sys.mjs:220:31\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementNotInteractableException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 1) Initialize Selenium WebDriver (Firefox)\n",
    "# ----------------------------------------------------------------\n",
    "browser = webdriver.Firefox()\n",
    "wait = WebDriverWait(browser, 10)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 2) Reject cookies only once\n",
    "# ----------------------------------------------------------------\n",
    "def reject_cookies_once(driver):\n",
    "    try:\n",
    "        iframe = wait.until(\n",
    "            EC.frame_to_be_available_and_switch_to_it(\n",
    "                (By.CSS_SELECTOR, \"iframe[id^='sp_message_iframe']\")\n",
    "            )\n",
    "        )\n",
    "        reject_button = wait.until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, \"//button[contains(text(), 'I do not agree')]\")\n",
    "            )\n",
    "        )\n",
    "        reject_button.click()\n",
    "        print(\"Cookies rejected.\")\n",
    "    except TimeoutException:\n",
    "        print(\"No cookie popup detected (maybe already dismissed).\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error handling cookies: {e}\")\n",
    "    finally:\n",
    "        driver.switch_to.default_content()\n",
    "        time.sleep(2)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 3) Extract articles from the current page\n",
    "# ----------------------------------------------------------------\n",
    "def extract_articles(driver):\n",
    "    articles = []\n",
    "    \n",
    "    # Wait for at least one “internal-link” anchor or timeout\n",
    "    try:\n",
    "        wait.until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"a[data-testid='internal-link']\"))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        print(\"No articles found on this page.\")\n",
    "        return articles\n",
    "    \n",
    "    # Grab all \"internal-link\" anchors\n",
    "    links = driver.find_elements(By.CSS_SELECTOR, \"a[data-testid='internal-link']\")\n",
    "    \n",
    "    for link_el in links:\n",
    "        try:\n",
    "            link = link_el.get_attribute(\"href\")\n",
    "            title = link_el.text.strip() or \"No title\"\n",
    "            summary = \"No summary\"  # If there's a summary, you'd find it with a separate selector\n",
    "            articles.append({\n",
    "                \"title\": title,\n",
    "                \"summary\": summary,\n",
    "                \"link\": link\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting an article: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Extracted {len(articles)} articles from this page.\")\n",
    "    return articles\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 4) Scrape all pages by clicking the “Next Page” button\n",
    "#    until it no longer exists or is disabled\n",
    "# ----------------------------------------------------------------\n",
    "def scrape_region(driver, url):\n",
    "    all_articles = []\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # Let the page render\n",
    "    \n",
    "    page_number = 1\n",
    "    \n",
    "    while True:\n",
    "        # Extract articles from the current page\n",
    "        page_articles = extract_articles(driver)\n",
    "        all_articles.extend(page_articles)\n",
    "        \n",
    "        # Try to find and click the “Next Page” button\n",
    "        try:\n",
    "            next_button = driver.find_element(By.CSS_SELECTOR, \"button[data-testid='pagination-next-button']\")\n",
    "            \n",
    "            # If it's disabled, we’re at the last page\n",
    "            if next_button.get_attribute(\"disabled\"):\n",
    "                print(f\"No more pages (button disabled) at page {page_number}.\")\n",
    "                break\n",
    "\n",
    "            # Scroll the button into view before clicking\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", next_button)\n",
    "            time.sleep(1)  # Give the page a moment to scroll\n",
    "\n",
    "            try:\n",
    "                # Attempt to click the button directly\n",
    "                next_button.click()\n",
    "            except ElementClickInterceptedException:\n",
    "                # If it's still obstructed, we can try an ActionChain click\n",
    "                print(\"Button was intercepted again. Trying ActionChains...\")\n",
    "                ActionChains(driver).move_to_element(next_button).click().perform()\n",
    "\n",
    "            page_number += 1\n",
    "            print(f\"Clicked 'Next Page' -> now on page {page_number}...\")\n",
    "            time.sleep(3)  # Wait for the next page to load\n",
    "            \n",
    "        except NoSuchElementException:\n",
    "            print(f\"No 'Next Page' button found after page {page_number}. Probably the last page.\")\n",
    "            break\n",
    "        except ElementNotInteractableException:\n",
    "            print(f\"'Next Page' button present but not interactable on page {page_number}. Stopping.\")\n",
    "            break\n",
    "    \n",
    "    return all_articles\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# MAIN SCRIPT\n",
    "# ----------------------------------------------------------------\n",
    "try:\n",
    "    # A) Reject cookies once (go to Europe's page first)\n",
    "    browser.get(\"https://www.bbc.com/news/world/europe\")\n",
    "    time.sleep(3)\n",
    "    reject_cookies_once(browser)\n",
    "\n",
    "    # B) List of regions\n",
    "    regions = [\n",
    "        \"world/europe\",\n",
    "        \"world/us_and_canada\",\n",
    "        \"uk\",\n",
    "        \"world/australia\",\n",
    "        \"world/asia\",\n",
    "        \"world/africa\",\n",
    "        \"world/latin_america\",\n",
    "        \"world/middle_east\"\n",
    "    ]\n",
    "    \n",
    "    all_articles = []\n",
    "    \n",
    "    # C) Scrape each region with multi-page approach\n",
    "    for region in regions:\n",
    "        print(f\"\\n--- Scraping region: {region} ---\")\n",
    "        url = f\"https://www.bbc.com/news/{region.lstrip('/')}\"\n",
    "        region_articles = scrape_region(browser, url)\n",
    "        all_articles.extend(region_articles)\n",
    "        # Brief pause between regions\n",
    "        time.sleep(2)\n",
    "        \n",
    "finally:\n",
    "    browser.quit()\n",
    "\n",
    "# D) Save to CSV\n",
    "with open(\"bbc_articles.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"title\", \"summary\", \"link\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(all_articles)\n",
    "\n",
    "print(f\"\\nDone! Extracted {len(all_articles)} articles in total.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Scraping Article Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Article Inspection\n",
    "\n",
    "# 2: Text Scraping Function\n",
    "\n",
    "# 3: Scrape All Articles\n",
    "\n",
    "# 4: Data Storage\n",
    "\n",
    "# 5: Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Preservation\n",
    "Keep the data that you have scraped so you can use it for your Group Project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
